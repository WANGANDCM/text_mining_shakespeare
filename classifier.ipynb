{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LSA to train a classifier for character gender recognition in Shakespeare plays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.externals.joblib import Memory\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first need to download punkt, our sentence tokenizer, and also a dictionary of stopwords that we'll use later to remove stopwords from the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We'll also need to find and assign genders to all characters and their associated texts. We'll use [this list of female characters](http://www.shakespeareswords.com/Special-Features-Female-Characters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "female_characters_df = pd.read_csv(\"female_characters.csv\")\n",
    "female_characters_df.character = female_characters_df.character.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>character</th>\n",
       "      <th>play_name</th>\n",
       "      <th>gender</th>\n",
       "      <th>replics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>lychorida</td>\n",
       "      <td>Pericles, Prince of Tyre</td>\n",
       "      <td>Female</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>gentlewoman</td>\n",
       "      <td>Macbeth</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>timandra</td>\n",
       "      <td>Timon of Athens</td>\n",
       "      <td>Female</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       character                 play_name  gender  replics\n",
       "139    lychorida  Pericles, Prince of Tyre  Female       11\n",
       "121  gentlewoman                   Macbeth  Female       24\n",
       "155     timandra           Timon of Athens  Female        4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_characters_df.sample(n= 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll de-serialize the data streams from our pickle file, which contain all texts from all of Shakespeare's plays along with the associated play, speaker, act/scene, and play genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('shakespeare_plays.pickle', 'rb') as handle:\n",
    "    speeches = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "speeches_df = pd.DataFrame(speeches)\n",
    "speeches_df.speaker = speeches_df.speaker.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>genre</th>\n",
       "      <th>play_name</th>\n",
       "      <th>scene</th>\n",
       "      <th>scene_name</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech_number</th>\n",
       "      <th>speech_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14217</th>\n",
       "      <td>2</td>\n",
       "      <td>History</td>\n",
       "      <td>Henry V</td>\n",
       "      <td>1</td>\n",
       "      <td>London. A street.</td>\n",
       "      <td>boy</td>\n",
       "      <td>24</td>\n",
       "      <td>Mine host Pistol, you must come to my master, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9206</th>\n",
       "      <td>2</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Taming of the Shrew</td>\n",
       "      <td>1</td>\n",
       "      <td>Padua. A room in BAPTISTA'S house.</td>\n",
       "      <td>hortensio</td>\n",
       "      <td>41</td>\n",
       "      <td>For fear, I promise you, if I look pale.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4875</th>\n",
       "      <td>4</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Measure for Measure</td>\n",
       "      <td>2</td>\n",
       "      <td>A room in the prison.</td>\n",
       "      <td>provost</td>\n",
       "      <td>31</td>\n",
       "      <td>It is a bitter deputy.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      act    genre            play_name scene  \\\n",
       "14217   2  History              Henry V     1   \n",
       "9206    2   Comedy  Taming of the Shrew     1   \n",
       "4875    4   Comedy  Measure for Measure     2   \n",
       "\n",
       "                               scene_name    speaker speech_number  \\\n",
       "14217                   London. A street.        boy            24   \n",
       "9206   Padua. A room in BAPTISTA'S house.  hortensio            41   \n",
       "4875                A room in the prison.    provost            31   \n",
       "\n",
       "                                             speech_text  \n",
       "14217  Mine host Pistol, you must come to my master, ...  \n",
       "9206            For fear, I promise you, if I look pale.  \n",
       "4875                              It is a bitter deputy.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_df.sample(n = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also double check that our list of plays are the same as the plays listed in the genders dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Two Gentlemen of Verona', 'The Tempest', 'Pericles, Prince of Tyre', 'Cymbeline', 'Twelfth Night', 'Timon of Athens', 'The Merchant of Venice', 'Julius Caesar', 'Henry VIII', \"A Midsummer Night's Dream\", 'Macbeth', \"All's Well That Ends Well\", \"Love's Labours Lost\", 'Much Ado About Nothing', 'Taming of the Shrew', 'TheMerry Wives of Windsor', 'King John', 'The Comedy of Errors', 'Othello', 'As You Like It', 'Richard II', 'King Lear', 'Troilus and Cressida', 'Richard III', 'Coriolanus', 'Hamlet', 'Measure for Measure', \"Winter's Tale\", 'Antony and Cleopatra', 'Henry V', 'Romeo and Juliet', 'Titus Andronicus'}\n"
     ]
    }
   ],
   "source": [
    "our_names = set(speeches_df.play_name)\n",
    "print(our_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "their_names = set(female_characters_df.play_name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Two Gentlemen of Verona', 'The Tempest', 'Pericles, Prince of Tyre', 'Cymbeline', 'Twelfth Night', 'Timon of Athens', 'The Merchant of Venice', 'Julius Caesar', 'Henry VIII', 'Macbeth', \"A Midsummer Night's Dream\", \"All's Well That Ends Well\", \"Love's Labours Lost\", 'Much Ado About Nothing', 'Taming of the Shrew', 'TheMerry Wives of Windsor', 'Henry IV', 'King John', 'The Comedy of Errors', 'Othello', 'As You Like It', 'Richard II', 'King Lear', 'Troilus and Cressida', 'Coriolanus', 'Richard III', 'Hamlet', 'Henry VI', 'Measure for Measure', \"Winter's Tale\", 'Antony and Cleopatra', 'Romeo and Juliet', 'Titus Andronicus', 'Henry V', 'The Two Noble Kinsmen', 'King Edward III'}\n"
     ]
    }
   ],
   "source": [
    "print(their_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check to see if our texts include any plays that aren't included in the genders dataframe and note that there are none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(our_names - their_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, it looks like the additional plays in the genders dataframe are those that Shakespeare co-authored, so looks we're looking okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'King Edward III', 'Henry IV', 'Henry VI', 'The Two Noble Kinsmen'}\n"
     ]
    }
   ],
   "source": [
    "print(their_names - our_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create sets of our speakers and add a 'female' column to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "our_speakers = set(speeches_df.speaker)\n",
    "their_speakers = set(female_characters_df.character)\n",
    "\n",
    "speeches_df['female'] = speeches_df.apply(lambda r : r['speaker'] in their_speakers, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also note that some of the texts are spoken by multiple people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>genre</th>\n",
       "      <th>play_name</th>\n",
       "      <th>scene</th>\n",
       "      <th>scene_name</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech_number</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>2</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>All's Well That Ends Well</td>\n",
       "      <td>3</td>\n",
       "      <td>Paris. The KING's palace.</td>\n",
       "      <td>all</td>\n",
       "      <td>34</td>\n",
       "      <td>We understand it, and thank heaven for you.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>4</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>All's Well That Ends Well</td>\n",
       "      <td>1</td>\n",
       "      <td>Without the Florentine camp.</td>\n",
       "      <td>all</td>\n",
       "      <td>26</td>\n",
       "      <td>Cargo, cargo, cargo, villiando par corbo, cargo.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3062</th>\n",
       "      <td>5</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Cymbeline</td>\n",
       "      <td>4</td>\n",
       "      <td>A British prison.</td>\n",
       "      <td>all</td>\n",
       "      <td>19</td>\n",
       "      <td>Thanks, Jupiter!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     act   genre                  play_name scene  \\\n",
       "268    2  Comedy  All's Well That Ends Well     3   \n",
       "587    4  Comedy  All's Well That Ends Well     1   \n",
       "3062   5  Comedy                  Cymbeline     4   \n",
       "\n",
       "                        scene_name speaker speech_number  \\\n",
       "268      Paris. The KING's palace.     all            34   \n",
       "587   Without the Florentine camp.     all            26   \n",
       "3062             A British prison.     all            19   \n",
       "\n",
       "                                           speech_text  female  \n",
       "268        We understand it, and thank heaven for you.   False  \n",
       "587   Cargo, cargo, cargo, villiando par corbo, cargo.   False  \n",
       "3062                                  Thanks, Jupiter!   False  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_df[speeches_df.speaker.str.startswith('all')][0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are examining differences in male/female speech in this analysis, we will discard all text spoken by multiple people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>genre</th>\n",
       "      <th>play_name</th>\n",
       "      <th>scene</th>\n",
       "      <th>scene_name</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speech_number</th>\n",
       "      <th>speech_text</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26939</th>\n",
       "      <td>4</td>\n",
       "      <td>Tragedy</td>\n",
       "      <td>Titus Andronicus</td>\n",
       "      <td>3</td>\n",
       "      <td>The same. A public place.</td>\n",
       "      <td>clown</td>\n",
       "      <td>18</td>\n",
       "      <td>Ay, of my pigeons, sir; nothing else.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13974</th>\n",
       "      <td>4</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Winter's Tale</td>\n",
       "      <td>4</td>\n",
       "      <td>The Shepherd's cottage.</td>\n",
       "      <td>autolycus</td>\n",
       "      <td>210</td>\n",
       "      <td>What advocate hast thou to him?</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10958</th>\n",
       "      <td>3</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Troilus and Cressida</td>\n",
       "      <td>1</td>\n",
       "      <td>Troy. Priam's palace.</td>\n",
       "      <td>paris</td>\n",
       "      <td>55</td>\n",
       "      <td>I spy.</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      act    genre             play_name scene                 scene_name  \\\n",
       "26939   4  Tragedy      Titus Andronicus     3  The same. A public place.   \n",
       "13974   4   Comedy         Winter's Tale     4    The Shepherd's cottage.   \n",
       "10958   3   Comedy  Troilus and Cressida     1      Troy. Priam's palace.   \n",
       "\n",
       "         speaker speech_number                            speech_text  female  \n",
       "26939      clown            18  Ay, of my pigeons, sir; nothing else.   False  \n",
       "13974  autolycus           210        What advocate hast thou to him?   False  \n",
       "10958      paris            55                                 I spy.   False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_df.drop(speeches_df[speeches_df.speaker.str.startswith('all')].index, inplace = True)\n",
    "speeches_df.sample(n = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataframe with all the data that we need, we turn our attention to the imbalance in male/female texts. We will have to take this into account when fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "female\n",
       "False    22275\n",
       "True      4728\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_df.groupby(['female']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 - male, 1 - female\n",
    "labels = [ 1 if f else 0 for f in speeches_df.female.values ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can perform text preprocessing, steming and tokenizing our words.\n",
    "\n",
    "This will not used in the final version as it makes CountVectorizer very slow. The built in functionality will be used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we note that we've successfully tokenized and stemmed our words.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Although before the solemn priest I have sworn,\n",
      "I will not bed her.\n"
     ]
    }
   ],
   "source": [
    "t = speeches_df.loc[334, 'speech_text']\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['although', 'befor', 'the', 'solemn', 'priest', 'I', 'have', 'sworn', ',', 'I', 'will', 'not', 'bed', 'her', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can begin the analysis, splitting our features into test and train sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = speeches_df['speech_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    labels, \n",
    "                                                    stratify = labels, \n",
    "                                                    test_size = 0.10, \n",
    "                                                    random_state = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a feature space, perform dimension reduction, and search for the best preforming parameters. We'll try three models: an SGDClassifier, RandomForestClassifier, and KNeighborsClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree('pipeline_sgd', ignore_errors = True)\n",
    "os.makedirs('pipeline_sgd')\n",
    "\n",
    "pipe_sgd = Pipeline(\n",
    "    memory = 'pipeline',\n",
    "    steps=[\n",
    "        # Create feature space\n",
    "        ('vect', CountVectorizer(min_df=2, \n",
    "                                 stop_words='english', \n",
    "                                 lowercase=True,\n",
    "                                 strip_accents='unicode')),\n",
    "                                 #ngram_range=(2,3))\n",
    "        ('tfidf', TfidfTransformer()),        \n",
    "        # Perform LSA on the features\n",
    "        ('svd', TruncatedSVD()),\n",
    "        # faster than SVC, default loss is 'hinge'\n",
    "        ('clf', SGDClassifier(class_weight= 'balanced', \n",
    "                              verbose = 0, \n",
    "                              n_jobs = -1, \n",
    "                              max_iter = 1000))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_sgd = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)), # unigrams or bigrams\n",
    "    'tfidf__norm': ['l1', 'l2'],\n",
    "    'svd__n_components': [250, 300, 350],\n",
    "    'clf__alpha': [0.00001, 0.000001],\n",
    "    'clf__penalty': ('l2', 'elasticnet')\n",
    "}\n",
    "\n",
    "model_sgd = GridSearchCV(\n",
    "    pipe_sgd,\n",
    "    param_grid = param_grid_sgd,\n",
    "    cv = StratifiedKFold(random_state = 100),\n",
    "    scoring = 'f1',\n",
    "    verbose = 1,\n",
    "    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree('pipeline_rf', ignore_errors = True)\n",
    "os.makedirs('pipeline_rf')\n",
    "\n",
    "pipe_rf = Pipeline(\n",
    "    memory = 'pipeline',\n",
    "    steps=[\n",
    "        # Create feature space\n",
    "        ('vect', CountVectorizer(min_df=2, \n",
    "                                 stop_words='english', \n",
    "                                 lowercase=True,\n",
    "                                 strip_accents='unicode')),\n",
    "                                 #ngram_range=(2,3))\n",
    "        ('tfidf', TfidfTransformer()),        \n",
    "        # Perform LSA on the features\n",
    "        ('svd', TruncatedSVD()),\n",
    "        ('rf', RandomForestClassifier(criterion='gini',\n",
    "                                       min_samples_split=2, \n",
    "                                       min_samples_leaf=1, \n",
    "                                       min_weight_fraction_leaf=0.0, \n",
    "                                       max_features='auto', \n",
    "                                       max_leaf_nodes=None, \n",
    "                                       min_impurity_decrease=0.0, \n",
    "                                       min_impurity_split=None, \n",
    "                                       bootstrap=True, \n",
    "                                       oob_score=False, \n",
    "                                       n_jobs=1, \n",
    "                                       random_state=None, \n",
    "                                       verbose=0, \n",
    "                                       warm_start=False, \n",
    "                                       class_weight=None))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_rf = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)), # unigrams or bigrams\n",
    "    'tfidf__norm': ['l1', 'l2'],\n",
    "    'svd__n_components': [250, 300, 350],\n",
    "    'rf__n_estimators':[5,10,15]\n",
    "}\n",
    "\n",
    "model_rf = GridSearchCV(\n",
    "    pipe_rf,\n",
    "    param_grid = param_grid_rf,\n",
    "    cv = StratifiedKFold(random_state = 100),\n",
    "    scoring = 'f1',\n",
    "    verbose = 1,\n",
    "    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shutil.rmtree('pipeline_knn', ignore_errors = True)\n",
    "os.makedirs('pipeline_knn')\n",
    "\n",
    "pipe_knn = Pipeline(\n",
    "    memory = 'pipeline',\n",
    "    steps=[\n",
    "        # Create feature space\n",
    "        ('vect', CountVectorizer(min_df=2, \n",
    "                                 stop_words='english', \n",
    "                                 lowercase=True,\n",
    "                                 strip_accents='unicode')),\n",
    "                                 #ngram_range=(2,3))\n",
    "        ('tfidf', TfidfTransformer()),        \n",
    "        # Perform LSA on the features\n",
    "        ('svd', TruncatedSVD()),\n",
    "        ('knn',KNeighborsClassifier(weights='uniform', \n",
    "                                    algorithm='auto', \n",
    "                                    p=2, \n",
    "                                    metric='minkowski', \n",
    "                                    metric_params=None, \n",
    "                                    n_jobs=1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_knn = {\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)), # unigrams or bigrams\n",
    "    'tfidf__norm': ['l1', 'l2'],\n",
    "    'svd__n_components': [250, 300, 350],\n",
    "    'knn__n_neighbors':[3,4,5,6,7,8]\n",
    "}\n",
    "\n",
    "model_knn = GridSearchCV(\n",
    "    pipe_knn,\n",
    "    param_grid = param_grid_knn,\n",
    "    cv = StratifiedKFold(random_state = 100),\n",
    "    scoring = 'f1',\n",
    "    verbose = 1,\n",
    "    n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 144 out of 144 | elapsed: 23.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 50.9min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 246.2min\n",
      "[Parallel(n_jobs=-1)]: Done 216 out of 216 | elapsed: 280.4min finished\n"
     ]
    }
   ],
   "source": [
    "model_sgd = model_sgd.fit(X_train, y_train)\n",
    "model_rf = model_rf.fit(X_train, y_train)\n",
    "model_knn = model_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at how the model's performance varied with different parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  clf__alpha clf__penalty  mean_test_score svd__n_components tfidf__norm\n",
      "0      1e-05           l2         0.283419               250          l1\n",
      "1      1e-05           l2         0.251819               250          l1\n",
      "2      1e-05           l2         0.321952               250          l2\n",
      "3      1e-05           l2         0.325283               250          l2\n",
      "4      1e-05           l2         0.289454               300          l1\n",
      "   mean_test_score rf__n_estimators svd__n_components tfidf__norm\n",
      "0         0.131355                5               250          l1\n",
      "1         0.145271                5               250          l1\n",
      "2         0.141113                5               250          l2\n",
      "3         0.138767                5               250          l2\n",
      "4         0.131378                5               300          l1\n",
      "  knn__n_neighbors  mean_test_score svd__n_components tfidf__norm\n",
      "0                3         0.152070               250          l1\n",
      "1                3         0.152254               250          l1\n",
      "2                3         0.152794               250          l2\n",
      "3                3         0.161234               250          l2\n",
      "4                3         0.154261               300          l1\n"
     ]
    }
   ],
   "source": [
    "results_sgd = pd.DataFrame({'mean_test_score': np.array(model_sgd.cv_results_['mean_test_score']),\n",
    "                        'tfidf__norm': np.array(model_sgd.cv_results_['param_tfidf__norm']),\n",
    "                        'svd__n_components': np.array(model_sgd.cv_results_['param_svd__n_components']),\n",
    "                        'clf__alpha': np.array(model_sgd.cv_results_['param_clf__alpha']),\n",
    "                        'clf__penalty': np.array(model_sgd.cv_results_['param_clf__penalty'])})\n",
    "\n",
    "results_rf = pd.DataFrame({'mean_test_score': np.array(model_rf.cv_results_['mean_test_score']),\n",
    "                        'tfidf__norm': np.array(model_rf.cv_results_['param_tfidf__norm']),\n",
    "                        'svd__n_components': np.array(model_rf.cv_results_['param_svd__n_components']),\n",
    "                        'rf__n_estimators': np.array(model_rf.cv_results_['param_rf__n_estimators'])})\n",
    "\n",
    "results_knn = pd.DataFrame({'mean_test_score': np.array(model_knn.cv_results_['mean_test_score']),\n",
    "                        'tfidf__norm': np.array(model_knn.cv_results_['param_tfidf__norm']),\n",
    "                        'svd__n_components': np.array(model_knn.cv_results_['param_svd__n_components']),\n",
    "                        'knn__n_neighbors': np.array(model_knn.cv_results_['param_knn__n_neighbors'])})\n",
    "\n",
    "print(results_sgd.head())\n",
    "print(results_rf.head())\n",
    "print(results_knn.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the best set of parameters for each of the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'clf__alpha': 1e-05, 'clf__penalty': 'elasticnet', 'svd__n_components': 350, 'tfidf__norm': 'l2', 'vect__ngram_range': (1, 1)} with a score of 0.34\n",
      "\n",
      "The best parameters are {'rf__n_estimators': 5, 'svd__n_components': 250, 'tfidf__norm': 'l1', 'vect__ngram_range': (1, 2)} with a score of 0.15\n",
      "\n",
      "The best parameters are {'knn__n_neighbors': 3, 'svd__n_components': 350, 'tfidf__norm': 'l2', 'vect__ngram_range': (1, 2)} with a score of 0.16\n"
     ]
    }
   ],
   "source": [
    "print(\"The best parameters are %s with a score of %0.2f\" % (model_sgd.best_params_, model_sgd.best_score_))\n",
    "print()\n",
    "print(\"The best parameters are %s with a score of %0.2f\" % (model_rf.best_params_, model_rf.best_score_))\n",
    "print()\n",
    "print(\"The best parameters are %s with a score of %0.2f\" % (model_knn.best_params_, model_knn.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can test on our test data and compare the results of the best set of parameters for each of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat_sgd = model_sgd.predict(X_test)\n",
    "y_hat_rf = model_rf.predict(X_test)\n",
    "y_hat_knn = model_knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.65      0.74      2228\n",
      "          1       0.23      0.49      0.31       473\n",
      "\n",
      "avg / total       0.75      0.62      0.66      2701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat_sgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.93      0.88      2228\n",
      "          1       0.22      0.09      0.13       473\n",
      "\n",
      "avg / total       0.72      0.78      0.75      2701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.93      0.87      2228\n",
      "          1       0.19      0.08      0.12       473\n",
      "\n",
      "avg / total       0.72      0.78      0.74      2701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_hat_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare this against using only the training set class distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = Pipeline(\n",
    "    steps=[\n",
    "        ('vect', CountVectorizer()), \n",
    "        ('clf', DummyClassifier(strategy='stratified', random_state=100))\n",
    "    ]\n",
    ")\n",
    "dummy = dummy.fit(X_train, y_train)\n",
    "y_dummy = dummy.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for the dummy classifier\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.84      0.83      2228\n",
      "          1       0.18      0.16      0.17       473\n",
      "\n",
      "avg / total       0.71      0.72      0.72      2701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification report for the dummy classifier')\n",
    "print(classification_report(y_test, y_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the dummy classifier against our own,it looks like our classifiers can do only slightly better in recognizing female characters. Overall we think we've failed to achive a significant improvement over the dummy classifier. \n",
    "\n",
    "We have to conclude that it is not possible to recoginze the characters' gender just by one speech. Additionally, we think it is a hard task and better results could be achieved if we used a combination of all speeches per character as the observations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
